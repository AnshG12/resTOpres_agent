@incollection{Bengio+chapter2007,
author = {Bengio, Yoshua and LeCun, Yann},
booktitle = {Large Scale Kernel Machines},
publisher = {MIT Press},
title = {Scaling Learning Algorithms Towards {AI}},
year = {2007}
}

@article{Hinton06,
author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee Whye},
journal = {Neural Computation},
pages = {1527--1554},
title = {A Fast Learning Algorithm for Deep Belief Nets},
volume = {18},
year = {2006}
}

@book{goodfellow2016deep,
title={Deep learning},
author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
volume={1},
year={2016},
publisher={MIT Press}
}
@misc{openai2024openaio1card,
      title={OpenAI o1 System Card}, 
      author={OpenAI},
      year={2024},
      eprint={2412.16720},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2412.16720}, 
}

@misc{deepseekai2025deepseekr1incentivizingreasoningcapability,
      title={DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning}, 
      author={DeepSeek-AI},
      year={2025},
      eprint={2501.12948},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2501.12948}, 
}

@misc{qwq32b,
    title = {QwQ-32B: Embracing the Power of Reinforcement Learning},
    url = {https://qwenlm.github.io/blog/qwq-32b/},
    author = {{Qwen Team}},
    month = {March},
    year = {2025}
}

@article{qwen2.5,
      title={Qwen2.5 Technical Report}, 
      author={An Yang and Baosong Yang and Beichen Zhang and Binyuan Hui and Bo Zheng and Bowen Yu and Chengyuan Li and Dayiheng Liu and Fei Huang and Haoran Wei and Huan Lin and Jian Yang and Jianhong Tu and Jianwei Zhang and Jianxin Yang and Jiaxi Yang and Jingren Zhou and Junyang Lin and Kai Dang and Keming Lu and Keqin Bao and Kexin Yang and Le Yu and Mei Li and Mingfeng Xue and Pei Zhang and Qin Zhu and Rui Men and Runji Lin and Tianhao Li and Tianyi Tang and Tingyu Xia and Xingzhang Ren and Xuancheng Ren and Yang Fan and Yang Su and Yichang Zhang and Yu Wan and Yuqiong Liu and Zeyu Cui and Zhenru Zhang and Zihan Qiu},
      journal={arXiv preprint arXiv:2412.15115},
      year={2024}
}

@misc{valmeekam2023planbenchextensiblebenchmarkevaluating,
      title={PlanBench: An Extensible Benchmark for Evaluating Large Language Models on Planning and Reasoning about Change}, 
      author={Karthik Valmeekam and Matthew Marquez and Alberto Olmo and Sarath Sreedharan and Subbarao Kambhampati},
      year={2023},
      eprint={2206.10498},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2206.10498}, 
}

@misc{park2025iclrincontextlearningrepresentations,
      title={ICLR: In-Context Learning of Representations}, 
      author={Core Francisco Park and Andrew Lee and Ekdeep Singh Lubana and Yongyi Yang and Maya Okawa and Kento Nishi and Martin Wattenberg and Hidenori Tanaka},
      year={2025},
      eprint={2501.00070},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2501.00070}, 
}
@misc{valmeekam2024llmscantplanlrms,
      title={LLMs Still Can't Plan; Can LRMs? A Preliminary Evaluation of OpenAI's o1 on PlanBench}, 
      author={Karthik Valmeekam and Kaya Stechly and Subbarao Kambhampati},
      year={2024},
      eprint={2409.13373},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2409.13373}, 
}
@misc{venhoff2025understandingreasoningthinkinglanguage,
      title={Understanding Reasoning in Thinking Language Models via Steering Vectors}, 
      author={Constantin Venhoff and Iván Arcuschin and Philip Torr and Arthur Conmy and Neel Nanda},
      year={2025},
      eprint={2506.18167},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2506.18167}, 
}
@misc{zhang2025finitestateautomatainside,
      title={Finite State Automata Inside Transformers with Chain-of-Thought: A Mechanistic Study on State Tracking}, 
      author={Yifan Zhang and Wenyu Du and Dongming Jin and Jie Fu and Zhi Jin},
      year={2025},
      eprint={2502.20129},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2502.20129}, 
}

@techreport{openai2025o3o4mini,
  title={o3 and o4-mini System Card},
  author={OpenAI},
  institution={OpenAI},
  year={2025},
  url={https://cdn.openai.com/pdf/2221c875-02dc-4789-800b-e7758f3722c1/o3-and-o4-mini-system-card.pdf},
  type={System Card}
}

@misc{ipc1998,
  title={International Planning Competition},
  author={{IPC}},
  howpublished={\url{https://www.icaps-conference.org/competitions}},
  year={1998},
  note={Accessed: \today}
}
@misc{shojaee2025illusionthinkingunderstandingstrengths,
      title={The Illusion of Thinking: Understanding the Strengths and Limitations of Reasoning Models via the Lens of Problem Complexity}, 
      author={Parshin Shojaee and Iman Mirzadeh and Keivan Alizadeh and Maxwell Horton and Samy Bengio and Mehrdad Farajtabar},
      year={2025},
      eprint={2506.06941},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2506.06941}, 
}
@misc{todd2024functionvectorslargelanguage,
      title={Function Vectors in Large Language Models}, 
      author={Eric Todd and Millicent L. Li and Arnab Sen Sharma and Aaron Mueller and Byron C. Wallace and David Bau},
      year={2024},
      eprint={2310.15213},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2310.15213}, 
}
@misc{hendel2023incontextlearningcreatestask,
      title={In-Context Learning Creates Task Vectors}, 
      author={Roee Hendel and Mor Geva and Amir Globerson},
      year={2023},
      eprint={2310.15916},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2310.15916}, 
}
@misc{arditi2024refusallanguagemodelsmediated,
      title={Refusal in Language Models Is Mediated by a Single Direction}, 
      author={Andy Arditi and Oscar Obeso and Aaquib Syed and Daniel Paleka and Nina Panickssery and Wes Gurnee and Neel Nanda},
      year={2024},
      eprint={2406.11717},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2406.11717}, 
}
@misc{lambert2025tulu3pushingfrontiers,
      title={Tulu 3: Pushing Frontiers in Open Language Model Post-Training}, 
      author={Nathan Lambert and Jacob Morrison and Valentina Pyatkin and Shengyi Huang and Hamish Ivison and Faeze Brahman and Lester James V. Miranda and Alisa Liu and Nouha Dziri and Shane Lyu and Yuling Gu and Saumya Malik and Victoria Graf and Jena D. Hwang and Jiangjiang Yang and Ronan Le Bras and Oyvind Tafjord and Chris Wilhelm and Luca Soldaini and Noah A. Smith and Yizhong Wang and Pradeep Dasigi and Hannaneh Hajishirzi},
      year={2025},
      eprint={2411.15124},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2411.15124}, 
}
@misc{shao2024deepseekmathpushinglimitsmathematical,
      title={DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models}, 
      author={Zhihong Shao and Peiyi Wang and Qihao Zhu and Runxin Xu and Junxiao Song and Xiao Bi and Haowei Zhang and Mingchuan Zhang and Y. K. Li and Y. Wu and Daya Guo},
      year={2024},
      eprint={2402.03300},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.03300}, 
}
@misc{xu2025largereasoningmodelssurvey,
      title={Towards Large Reasoning Models: A Survey of Reinforced Reasoning with Large Language Models}, 
      author={Fengli Xu and Qianyue Hao and Zefang Zong and Jingwei Wang and Yunke Zhang and Jingyi Wang and Xiaochong Lan and Jiahui Gong and Tianjian Ouyang and Fanjin Meng and Chenyang Shao and Yuwei Yan and Qinglong Yang and Yiwen Song and Sijian Ren and Xinyuan Hu and Yu Li and Jie Feng and Chen Gao and Yong Li},
      year={2025},
      eprint={2501.09686},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2501.09686}, 
}
@misc{bogdan2025thoughtanchorsllmreasoning,
      title={Thought Anchors: Which LLM Reasoning Steps Matter?}, 
      author={Paul C. Bogdan and Uzay Macar and Neel Nanda and Arthur Conmy},
      year={2025},
      eprint={2506.19143},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2506.19143}, 
}
@misc{lee2025geometryselfverificationtaskspecificreasoning,
      title={The Geometry of Self-Verification in a Task-Specific Reasoning Model}, 
      author={Andrew Lee and Lihao Sun and Chris Wendler and Fernanda Viégas and Martin Wattenberg},
      year={2025},
      eprint={2504.14379},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2504.14379}, 
}
@misc{galichin2025icoveredbaseshere,
      title={I Have Covered All the Bases Here: Interpreting Reasoning Features in Large Language Models via Sparse Autoencoders}, 
      author={Andrey Galichin and Alexey Dontsov and Polina Druzhinina and Anton Razzhigaev and Oleg Y. Rogov and Elena Tutubalina and Ivan Oseledets},
      year={2025},
      eprint={2503.18878},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2503.18878}, 
}
@misc{zou2025representationengineeringtopdownapproach,
      title={Representation Engineering: A Top-Down Approach to AI Transparency}, 
      author={Andy Zou and Long Phan and Sarah Chen and James Campbell and Phillip Guo and Richard Ren and Alexander Pan and Xuwang Yin and Mantas Mazeika and Ann-Kathrin Dombrowski and Shashwat Goel and Nathaniel Li and Michael J. Byun and Zifan Wang and Alex Mallen and Steven Basart and Sanmi Koyejo and Dawn Song and Matt Fredrikson and J. Zico Kolter and Dan Hendrycks},
      year={2025},
      eprint={2310.01405},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2310.01405}, 
}
@misc{ward2025reasoningfinetuningrepurposeslatentrepresentations,
      title={Reasoning-Finetuning Repurposes Latent Representations in Base Models}, 
      author={Jake Ward and Chuqiao Lin and Constantin Venhoff and Neel Nanda},
      year={2025},
      eprint={2507.12638},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2507.12638}, 
}
@misc{minder2025overcomingsparsityartifactscrosscoders,
      title={Overcoming Sparsity Artifacts in Crosscoders to Interpret Chat-Tuning}, 
      author={Julian Minder and Clément Dumas and Caden Juang and Bilal Chugtai and Neel Nanda},
      year={2025},
      eprint={2504.02922},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2504.02922}, 
}
@misc{zhao2025activationcontrolefficientlyeliciting,
      title={Activation Control for Efficiently Eliciting Long Chain-of-thought Ability of Language Models}, 
      author={Zekai Zhao and Qi Liu and Kun Zhou and Zihan Liu and Yifei Shao and Zhiting Hu and Biwei Huang},
      year={2025},
      eprint={2505.17697},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2505.17697}, 
}
@misc{minder2025controllablecontextsensitivityknob,
      title={Controllable Context Sensitivity and the Knob Behind It}, 
      author={Julian Minder and Kevin Du and Niklas Stoehr and Giovanni Monea and Chris Wendler and Robert West and Ryan Cotterell},
      year={2025},
      eprint={2411.07404},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2411.07404}, 
}
@misc{arefin2025seqvcrpreventingcollapseintermediate,
      title={Seq-VCR: Preventing Collapse in Intermediate Transformer Representations for Enhanced Reasoning}, 
      author={Md Rifat Arefin and Gopeshh Subbaraj and Nicolas Gontier and Yann LeCun and Irina Rish and Ravid Shwartz-Ziv and Christopher Pal},
      year={2025},
      eprint={2411.02344},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2411.02344}, 
}
@misc{dutta2024thinkstepbystepmechanisticunderstanding,
      title={How to think step-by-step: A mechanistic understanding of chain-of-thought reasoning}, 
      author={Subhabrata Dutta and Joykirat Singh and Soumen Chakrabarti and Tanmoy Chakraborty},
      year={2024},
      eprint={2402.18312},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.18312}, 
}
@misc{gandhi2025cognitivebehaviorsenableselfimproving,
      title={Cognitive Behaviors that Enable Self-Improving Reasoners, or, Four Habits of Highly Effective STaRs}, 
      author={Kanishk Gandhi and Ayush Chakravarthy and Anikait Singh and Nathan Lile and Noah D. Goodman},
      year={2025},
      eprint={2503.01307},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2503.01307}, 
}
@misc{tang2025unlockinggenerallongchainofthought,
      title={Unlocking General Long Chain-of-Thought Reasoning Capabilities of Large Language Models via Representation Engineering}, 
      author={Xinyu Tang and Xiaolei Wang and Zhihao Lv and Yingqian Min and Wayne Xin Zhao and Binbin Hu and Ziqi Liu and Zhiqiang Zhang},
      year={2025},
      eprint={2503.11314},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2503.11314}, 
}
@misc{hou2023mechanisticinterpretationmultistepreasoning,
      title={Towards a Mechanistic Interpretation of Multi-Step Reasoning Capabilities of Language Models}, 
      author={Yifan Hou and Jiaoda Li and Yu Fei and Alessandro Stolfo and Wangchunshu Zhou and Guangtao Zeng and Antoine Bosselut and Mrinmaya Sachan},
      year={2023},
      eprint={2310.14491},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2310.14491}, 
}



@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019},
  url={https://insightcivic.s3.us-east-1.amazonaws.com/language-models.pdf}
}

@misc{ryanizebib, 
    title={Ryanize bib},
    author={Vilém Zouhar},
    year={2023},
    url={https://github.com/zouharvi/ryanize-bib},
}

@inproceedings{kojima2022large, 
    title={Large Language Models are Zero-Shot Reasoners},
    author={Takeshi Kojima and Shixiang Shane Gu and Machel Reid and Yutaka Matsuo and Yusuke Iwasawa},
    booktitle={ICML 2022 Workshop on Knowledge Retrieval and Language Models},
    year={2022},
    url={https://openreview.net/forum?id=6p3AuaHAFiN},
}

@inproceedings{yang2024large, 
    title={Large Language Models as Optimizers},
    author={Chengrun Yang and Xuezhi Wang and Yifeng Lu and Hanxiao Liu and Quoc V Le and Denny Zhou and Xinyun Chen},
    booktitle={The Twelfth International Conference on Learning Representations},
    year={2024},
    url={https://openreview.net/forum?id=Bb4VGOWELI},
}

@article{parzen, 
    issn={00034851},
    url={http://www.jstor.org/stable/2237880},
    author={Emanuel Parzen},
    journal={The Annals of Mathematical Statistics},
    number={3},
    pages={1065--1076},
    title={On Estimation of a Probability Density Function and Mode},
    urldate={2024-09-28},
    volume={33},
    year={1962},
}

@inproceedings{geva-etal-2022-transformer, 
    title={Transformer Feed-Forward Layers Build Predictions by Promoting Concepts in the Vocabulary Space},
    author={Geva, Mor  and Caciularu, Avi  and Wang, Kevin  and Goldberg, Yoav},
    editor={Goldberg, Yoav  and Kozareva, Zornitsa  and Zhang, Yue},
    booktitle={Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
    month={dec},
    year={2022},
    address={Abu Dhabi, United Arab Emirates},
    publisher={Association for Computational Linguistics},
    url={https://aclanthology.org/2022.emnlp-main.3},
    doi={10.18653/v1/2022.emnlp-main.3},
    pages={30--45},
    abstract={Transformer-based language models (LMs) are at the core of modern NLP, but their internal prediction construction process is opaque and largely not understood. In this work, we make a substantial step towards unveiling this underlying prediction process, by reverse-engineering the operation of the feed-forward network (FFN) layers, one of the building blocks of transformer models. We view the token representation as a changing distribution over the vocabulary, and the output from each FFN layer as an additive update to that distribution. Then, we analyze the FFN updates in the vocabulary space, showing that each update can be decomposed to sub-updates corresponding to single FFN parameter vectors, each promoting concepts that are often human-interpretable. We then leverage these findings for controlling LM predictions, where we reduce the toxicity of GPT2 by almost 50{\%}, and for improving computation efficiency with a simple early exit rule, saving 20{\%} of computation on average.},
}

@misc{nostalgebraist, 
    author={nostalgebraist},
    url={https://www.lesswrong.com/posts/AcKRB8wDpdaN6v6ru/interpreting-gpt-the-logit-lens},
    year={2020},
    howpublished={LessWrong},
    title={Interpreting {GPT}: {The} Logit Lens},
}

@misc{lu2024investigatingbiasrepresentationsllama, 
    title={Investigating Bias Representations in Llama 2 Chat via Activation Steering},
    author={Dawn Lu and Nina Panickssery},
    year={2024},
    eprint={2402.00402},
    archiveprefix={arXiv},
    primaryclass={cs.CL},
    url={https://arxiv.org/abs/2402.00402},
}

@misc{jorgensen2023improvingactivationsteeringlanguage, 
    title={Improving Activation Steering in Language Models with Mean-Centring},
    author={Ole Jorgensen and Dylan Cope and Nandi Schoots and Murray Shanahan},
    year={2023},
    eprint={2312.03813},
    archiveprefix={arXiv},
    primaryclass={cs.CL},
    url={https://arxiv.org/abs/2312.03813},
}

@misc{wang2024trojanactivationattackredteaming, 
    title={Trojan Activation Attack: {Red-Teaming} Large Language Models using Activation Steering for Safety-Alignment},
    author={Haoran Wang and Kai Shu},
    year={2024},
    eprint={2311.09433},
    archiveprefix={arXiv},
    primaryclass={cs.CR},
    url={https://arxiv.org/abs/2311.09433},
}

@inproceedings{
stickland2024steeringeffectsimprovingpostdeployment,
title={Steering Without Side Effects: Improving Post-Deployment Control of Language Models},
author={Asa Cooper Stickland and Alexander Lyzhov and Jacob Pfau and Salsabila Mahdi and Samuel R. Bowman},
booktitle={Neurips Safe Generative AI Workshop 2024},
year={2024},
url={https://openreview.net/forum?id=tfXIZ8P4ZU}
}

@misc{nanda2022transformerlens, 
    title={TransformerLens},
    author={Neel Nanda and Joseph Bloom},
    year={2022},
    url={https://github.com/TransformerLensOrg/TransformerLens},
}

@inproceedings{neurips2019_bdbca288, 
    author={Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
    booktitle={Advances in Neural Information Processing Systems},
    editor={H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
    pages={},
    publisher={Curran Associates, Inc.},
    title={PyTorch: {An} Imperative Style, High-Performance Deep Learning Library},
    url={https://proceedings.neurips.cc/paper_files/paper/2019/file/bdbca288fee7f92f2bfa9f7012727740-Paper.pdf},
    volume={32},
    year={2019},
}

@misc{plotly, 
    author={{Plotly Technologies Inc.}},
    title={Collaborative data science},
    year={2015},
    url={https://plot.ly},
}

@article{harris2020array, 
    title={Array programming with {NumPy}},
    author={Charles R. Harris and K. Jarrod Millman and St{\'{e}}fan J. van der Walt and Ralf Gommers and Pauli Virtanen and David Cournapeau and Eric Wieser and Julian Taylor and Sebastian Berg and Nathaniel J. Smith and Robert Kern and Matti Picus and Stephan Hoyer and Marten H. van Kerkwijk and Matthew Brett and Allan Haldane and Jaime Fern{\'{a}}ndez del R{\'{i}}o and Mark Wiebe and Pearu Peterson and Pierre G{\'{e}}rard-Marchant and Kevin Sheppard and Tyler Reddy and Warren Weckesser and Hameer Abbasi and Christoph Gohlke and Travis E. Oliphant},
    year={2020},
    month={sep},
    journal={Nature},
    volume={585},
    number={7825},
    pages={357--362},
    doi={10.1038/s41586-020-2649-2},
    publisher={Springer Science and Business Media {LLC}},
    url={https://doi.org/10.1038/s41586-020-2649-2},
}

@inproceedings{mckinney-proc-scipy-2010, 
    author={ {W}es {M}c{K}inney },
    title={{D}ata {S}tructures for {S}tatistical {C}omputing in {P}ython},
    booktitle={ {P}roceedings of the 9th {P}ython in {S}cience {C}onference },
    pages={ 56 - 61 },
    year={ 2010 },
    editor={ {S}t\'efan van der {W}alt and {J}arrod {M}illman },
    doi={ 10.25080/Majora-92bf1922-00a },
    url={https://scipy.org},
}

@article{mcnemar1947note, 
    title={Note on the sampling error of the difference between correlated proportions or percentages},
    author={McNemar, Quinn},
    journal={Psychometrika},
    volume={12},
    number={2},
    pages={153--157},
    year={1947},
    publisher={Springer-Verlag New York},
    url={https://link.springer.com/article/10.1007/bf02295996},
}

@misc{vonrütte2024languagemodelsguidelatent, 
    title={A Language Model's Guide Through Latent Space},
    author={Dimitri von Rütte and Sotiris Anagnostidis and Gregor Bachmann and Thomas Hofmann},
    year={2024},
    eprint={2402.14433},
    archiveprefix={arXiv},
    primaryclass={cs.CL},
    url={https://arxiv.org/abs/2402.14433},
}

@inproceedings{
rahn2024controllinglargelanguagemodel,
title={Controlling Large Language Model Agents with Entropic Activation Steering},
author={Nate Rahn and Pierluca D'Oro and Marc G Bellemare},
booktitle={ICML 2024 Workshop on Mechanistic Interpretability},
year={2024},
url={https://openreview.net/forum?id=3eBdq2n848}
}

@inproceedings{
qiu2024spectraleditingactivationslarge,
title={Spectral Editing of Activations for Large Language Model Alignment},
author={Yifu Qiu and Zheng Zhao and Yftah Ziser and Anna Korhonen and Edoardo Ponti and Shay B Cohen},
booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
year={2024},
url={https://openreview.net/forum?id=pqYceEa87j}
}

@inproceedings{gurnee2024language, 
    title={Language Models Represent Space and Time},
    author={Wes Gurnee and Max Tegmark},
    booktitle={The Twelfth International Conference on Learning Representations},
    year={2024},
    url={https://openreview.net/forum?id=jE8xbmvFin},
}

@inproceedings{sharma2024towards, 
    title={Towards Understanding Sycophancy in Language Models},
    author={Mrinank Sharma and Meg Tong and Tomasz Korbak and David Duvenaud and Amanda Askell and Samuel R. Bowman and Esin DURMUS and Zac Hatfield-Dodds and Scott R Johnston and Shauna M Kravec and Timothy Maxwell and Sam McCandlish and Kamal Ndousse and Oliver Rausch and Nicholas Schiefer and Da Yan and Miranda Zhang and Ethan Perez},
    booktitle={The Twelfth International Conference on Learning Representations},
    year={2024},
    url={https://openreview.net/forum?id=tvhaxkMKAn},
}

@inproceedings{perez-etal-2023-discovering, 
    title={Discovering Language Model Behaviors with Model-Written Evaluations},
    author={Perez, Ethan  and Ringer, Sam  and Lukosiute, Kamile  and Nguyen, Karina  and Chen, Edwin  and Heiner, Scott  and Pettit, Craig  and Olsson, Catherine  and Kundu, Sandipan  and Kadavath, Saurav  and Jones, Andy  and Chen, Anna  and Mann, Benjamin  and Israel, Brian  and Seethor, Bryan  and McKinnon, Cameron  and Olah, Christopher  and Yan, Da  and Amodei, Daniela  and Amodei, Dario  and Drain, Dawn  and Li, Dustin  and Tran-Johnson, Eli  and Khundadze, Guro  and Kernion, Jackson  and Landis, James  and Kerr, Jamie  and Mueller, Jared  and Hyun, Jeeyoon  and Landau, Joshua  and Ndousse, Kamal  and Goldberg, Landon  and Lovitt, Liane  and Lucas, Martin  and Sellitto, Michael  and Zhang, Miranda  and Kingsland, Neerav  and Elhage, Nelson  and Joseph, Nicholas  and Mercado, Noemi  and DasSarma, Nova  and Rausch, Oliver  and Larson, Robin  and McCandlish, Sam  and Johnston, Scott  and Kravec, Shauna  and El Showk, Sheer  and Lanham, Tamera  and Telleen-Lawton, Timothy  and Brown, Tom  and Henighan, Tom  and Hume, Tristan  and Bai, Yuntao  and Hatfield-Dodds, Zac  and Clark, Jack  and Bowman, Samuel R.  and Askell, Amanda  and Grosse, Roger  and Hernandez, Danny  and Ganguli, Deep  and Hubinger, Evan  and Schiefer, Nicholas  and Kaplan, Jared},
    editor={Rogers, Anna  and Boyd-Graber, Jordan  and Okazaki, Naoaki},
    booktitle={Findings of the Association for Computational Linguistics: ACL 2023},
    month={jul},
    year={2023},
    address={Toronto, Canada},
    publisher={Association for Computational Linguistics},
    url={https://aclanthology.org/2023.findings-acl.847},
    doi={10.18653/v1/2023.findings-acl.847},
    pages={13387--13434},
    abstract={As language models (LMs) scale, they develop many novel behaviors, good and bad, exacerbating the need to evaluate how they behave. Prior work creates evaluations with crowdwork (which is time-consuming and expensive) or existing data sources (which are not always available). Here, we automatically generate evaluations with LMs. We explore approaches with varying amounts of human effort, from instructing LMs to write yes/no questions to making complex Winogender schemas with multiple stages of LM-based generation and filtering. Crowdworkers rate the examples as highly relevant and agree with 90-100{\%} of labels, sometimes more so than corresponding human-written datasets. We generate 154 datasets and discover new cases of inverse scaling where LMs get worse with size. Larger LMs repeat back a dialog user{'}s preferred answer ({``}sycophancy{''}) and express greater desire to pursue concerning goals like resource acquisition and goal preservation. We also find some of the first examples of inverse scaling in RL from Human Feedback (RLHF), where more RLHF makes LMs worse. For example, RLHF makes LMs express stronger political views (on gun rights and immigration) and a greater desire to avoid shut down. Overall, LM-written evaluations are high-quality and let us quickly discover many novel LM behaviors.},
}

@inproceedings{azaria-mitchell-2023-internal, 
    title={The Internal State of an {LLM} Knows When It{'}s Lying},
    author={Azaria, Amos  and Mitchell, Tom},
    editor={Bouamor, Houda  and Pino, Juan  and Bali, Kalika},
    booktitle={Findings of the Association for Computational Linguistics: EMNLP 2023},
    month={dec},
    year={2023},
    address={Singapore},
    publisher={Association for Computational Linguistics},
    url={https://aclanthology.org/2023.findings-emnlp.68},
    doi={10.18653/v1/2023.findings-emnlp.68},
    pages={967--976},
    abstract={While Large Language Models (LLMs) have shown exceptional performance in various tasks, one of their most prominent drawbacks is generating inaccurate or false information with a confident tone. In this paper, we provide evidence that the LLM{'}s internal state can be used to reveal the truthfulness of statements. This includes both statements provided to the LLM, and statements that the LLM itself generates. Our approach is to train a classifier that outputs the probability that a statement is truthful, based on the hidden layer activations of the LLM as it reads or generates the statement. Experiments demonstrate that given a set of test sentences, of which half are true and half false, our trained classifier achieves an average of 71{\%} to 83{\%} accuracy labeling which sentences are true versus false, depending on the LLM base model. Furthermore, we explore the relationship between our classifier{'}s performance and approaches based on the probability assigned to the sentence by the LLM. We show that while LLM-assigned sentence probability is related to sentence truthfulness, this probability is also dependent on sentence length and the frequencies of words in the sentence, resulting in our trained classifier providing a more reliable approach to detecting truthfulness, highlighting its potential to enhance the reliability of LLM-generated content and its practical applicability in real-world scenarios.},
}

@inproceedings{
cao2024personalizedsteeringlargelanguage,
title={Personalized Steering of Large Language Models: Versatile Steering Vectors Through Bi-directional Preference Optimization},
author={Yuanpu Cao and Tianrong Zhang and Bochuan Cao and Ziyi Yin and Lu Lin and Fenglong Ma and Jinghui Chen},
booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
year={2024},
url={https://openreview.net/forum?id=7qJFkuZdYo}
}

@misc{vanderweij2024extendingactivationsteeringbroad, 
    title={Extending Activation Steering to Broad Skills and Multiple Behaviours},
    author={Teun van der Weij and Massimo Poesio and Nandi Schoots},
    year={2024},
    eprint={2403.05767},
    archiveprefix={arXiv},
    primaryclass={cs.LG},
    url={https://arxiv.org/abs/2403.05767},
}

@inproceedings{jain2024what, 
    title={What Makes and Breaks Safety Fine-tuning? A Mechanistic Study},
    author={Samyak Jain and Ekdeep Singh Lubana and Kemal Oksuz and Tom Joy and Philip Torr and Amartya Sanyal and Puneet K. Dokania},
    booktitle={ICML 2024 Workshop on Mechanistic Interpretability},
    year={2024},
    url={https://openreview.net/forum?id=BS2CbUkJpy},
}

@inproceedings{burns2023discovering, 
    title={Discovering Latent Knowledge in Language Models Without Supervision},
    author={Collin Burns and Haotian Ye and Dan Klein and Jacob Steinhardt},
    booktitle={The Eleventh International Conference on Learning Representations },
    year={2023},
    url={https://openreview.net/forum?id=ETKGuby0hcs},
}

@inproceedings{shao-etal-2023-gold, 
    title={Gold Doesn{'}t Always Glitter: {Spectral} Removal of Linear and Nonlinear Guarded Attribute Information},
    author={Shao, Shun  and Ziser, Yftah  and Cohen, Shay B.},
    editor={Vlachos, Andreas  and Augenstein, Isabelle},
    booktitle={Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics},
    month={may},
    year={2023},
    address={Dubrovnik, Croatia},
    publisher={Association for Computational Linguistics},
    url={https://aclanthology.org/2023.eacl-main.118},
    doi={10.18653/v1/2023.eacl-main.118},
    pages={1611--1622},
    abstract={We describe a simple and effective method (Spectral Attribute removaL; SAL) to remove private or guarded information from neural representations. Our method uses matrix decomposition to project the input representations into directions with reduced covariance with the guarded information rather than maximal covariance as factorization methods normally use. We begin with linear information removal and proceed to generalize our algorithm to the case of nonlinear information removal using kernels. Our experiments demonstrate that our algorithm retains better main task performance after removing the guarded information compared to previous work. In addition, our experiments demonstrate that we need a relatively small amount of guarded attribute data to remove information about these attributes, which lowers the exposure to sensitive data and is more suitable for low-resource scenarios.},
}

@inproceedings{ravfogel-etal-2020-null, 
    title={Null It Out: {Guarding} Protected Attributes by Iterative Nullspace Projection},
    author={Ravfogel, Shauli  and Elazar, Yanai  and Gonen, Hila  and Twiton, Michael  and Goldberg, Yoav},
    editor={Jurafsky, Dan  and Chai, Joyce  and Schluter, Natalie  and Tetreault, Joel},
    booktitle={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
    month={jul},
    year={2020},
    address={Online},
    publisher={Association for Computational Linguistics},
    url={https://aclanthology.org/2020.acl-main.647},
    doi={10.18653/v1/2020.acl-main.647},
    pages={7237--7256},
    abstract={The ability to control for the kinds of information encoded in neural representation has a variety of use cases, especially in light of the challenge of interpreting these models. We present Iterative Null-space Projection (INLP), a novel method for removing information from neural representations. Our method is based on repeated training of linear classifiers that predict a certain property we aim to remove, followed by projection of the representations on their null-space. By doing so, the classifiers become oblivious to that target property, making it hard to linearly separate the data according to it. While applicable for multiple uses, we evaluate our method on bias and fairness use-cases, and show that our method is able to mitigate bias in word embeddings, as well as to increase fairness in a setting of multi-class classification.},
}

@misc{guerner2024geometricnotioncausalprobing, 
    title={A Geometric Notion of Causal Probing},
    author={Clément Guerner and Anej Svete and Tianyu Liu and Alexander Warstadt and Ryan Cotterell},
    year={2024},
    eprint={2307.15054},
    archiveprefix={arXiv},
    primaryclass={cs.CL},
    url={https://arxiv.org/abs/2307.15054},
}

@inproceedings{belrose2023leace, 
    title={{LEACE}: {Perfect} linear concept erasure in closed form},
    author={Nora Belrose and David Schneider-Joseph and Shauli Ravfogel and Ryan Cotterell and Edward Raff and Stella Biderman},
    booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
    year={2023},
    url={https://openreview.net/forum?id=awIpKpwTwF},
}

@article{olah2024lrh, 
    title={What is a Linear Representation? What is a Multidimensional Feature?},
    author={Olah, Christopher},
    year={2024},
    journal={Transformer Circuits Thread},
    url={https://transformer-circuits.pub/2024/july-update/},
}

@inproceedings{nanda-etal-2023-emergent, 
    title={Emergent Linear Representations in World Models of Self-Supervised Sequence Models},
    author={Nanda, Neel  and Lee, Andrew  and Wattenberg, Martin},
    editor={Belinkov, Yonatan  and Hao, Sophie  and Jumelet, Jaap  and Kim, Najoung  and McCarthy, Arya  and Mohebbi, Hosein},
    booktitle={Proceedings of the 6th BlackboxNLP Workshop: Analyzing and Interpreting Neural Networks for NLP},
    month={dec},
    year={2023},
    address={Singapore},
    publisher={Association for Computational Linguistics},
    url={https://aclanthology.org/2023.blackboxnlp-1.2},
    doi={10.18653/v1/2023.blackboxnlp-1.2},
    pages={16--30},
    abstract={How do sequence models represent their decision-making process? Prior work suggests that Othello-playing neural network learned nonlinear models of the board state (Li et al., 2023a). In this work, we provide evidence of a closely related linear representation of the board. In particular, we show that probing for {``}my colour{''} vs. {``}opponent{'}s colour{''} may be a simple yet powerful way to interpret the model{'}s internal state. This precise understanding of the internal representations allows us to control the model{'}s behaviour with simple vector arithmetic. Linear representations enable significant interpretability progress, which we demonstrate with further exploration of how the world model is computed.},
}

@inproceedings{csordás2024recurrentneuralnetworkslearn,
    title = "Recurrent Neural Networks Learn to Store and Generate Sequences using Non-Linear Representations",
    author = "Csord{\'a}s, R{\'o}bert  and
      Potts, Christopher  and
      Manning, Christopher D  and
      Geiger, Atticus",
    editor = "Belinkov, Yonatan  and
      Kim, Najoung  and
      Jumelet, Jaap  and
      Mohebbi, Hosein  and
      Mueller, Aaron  and
      Chen, Hanjie",
    booktitle = "Proceedings of the 7th BlackboxNLP Workshop: Analyzing and Interpreting Neural Networks for NLP",
    month = nov,
    year = "2024",
    address = "Miami, Florida, US",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.blackboxnlp-1.17/",
    doi = "10.18653/v1/2024.blackboxnlp-1.17",
    pages = "248--262",
    abstract = "The Linear Representation Hypothesis (LRH) states that neural networks learn to encode concepts as directions in activation space, and a strong version of the LRH states that models learn only such encodings. In this paper, we present a counterexample to this strong LRH: when trained to repeat an input token sequence, gated recurrent neural networks (RNNs) learn to represent the token at each position with a particular order of magnitude, rather than a direction. These representations have layered features that are impossible to locate in distinct linear subspaces. To show this, we train interventions to predict and manipulate tokens by learning the scaling factor corresponding to each sequence position. These interventions indicate that the smallest RNNs find only this magnitude-based solution, while larger RNNs have linear representations. These findings strongly indicate that interpretability research should not be confined by the LRH."
}


@inproceedings{
engels2024languagemodelfeatureslinear,
title={Not All Language Model Features Are Linear},
author={Joshua Engels and Eric J Michaud and Isaac Liao and Wes Gurnee and Max Tegmark},
booktitle={The Thirteenth International Conference on Learning Representations},
year={2025},
url={https://openreview.net/forum?id=d63a4AM4hb}
}

@inproceedings{pmlr-v235-park24c, 
    title={The Linear Representation Hypothesis and the Geometry of Large Language Models},
    author={Park, Kiho and Choe, Yo Joong and Veitch, Victor},
    booktitle={	 {Proceedings of the 41st International Conference on Machine Learning}},
    pages={	 {39643--39666}},
    year={	 {2024}},
    editor={	 {Salakhutdinov, Ruslan and Kolter, Zico and Heller, Katherine and Weller, Adrian and Oliver, Nuria and Scarlett, Jonathan and Berkenkamp, Felix}},
    volume={	 {235}},
    series={	 {Proceedings of Machine Learning Research}},
    month={	 {21--27 Jul}},
    publisher={PMLR},
    pdf={	 {https://raw.githubusercontent.com/mlresearch/v235/main/assets/park24c/park24c.pdf}},
    url={	 {https://proceedings.mlr.press/v235/park24c.html}},
    abstract={	 {Informally, the "linear representation hypothesis" is the idea that high-level concepts are represented linearly as directions in some representation space. In this paper, we address two closely related questions: What does "linear representation" actually mean? And, how do we make sense of geometric notions (e.g., cosine similarity and projection) in the representation space? To answer these, we use the language of counterfactuals to give two formalizations of linear representation, one in the output (word) representation space, and one in the input (context) space. We then prove that these connect to linear probing and model steering, respectively. To make sense of geometric notions, we use the formalization to identify a particular (non-Euclidean) inner product that respects language structure in a sense we make precise. Using this causal inner product, we show how to unify all notions of linear representation. In particular, this allows the construction of probes and steering vectors using counterfactual pairs. Experiments with LLaMA-2 demonstrate the existence of linear representations of concepts, the connection to interpretation and control, and the fundamental role of the choice of inner product.}},
}

@inproceedings{nips2016_a486cd07, 
    author={Bolukbasi, Tolga and Chang, Kai-Wei and Zou, James Y and Saligrama, Venkatesh and Kalai, Adam T},
    booktitle={Advances in Neural Information Processing Systems},
    editor={D. Lee and M. Sugiyama and U. Luxburg and I. Guyon and R. Garnett},
    pages={},
    publisher={Curran Associates, Inc.},
    title={Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings},
    url={https://proceedings.neurips.cc/paper_files/paper/2016/file/a486cd07e4ac3d270571622f4f316ec5-Paper.pdf},
    volume={29},
    year={2016},
}

@inproceedings{nips2013_9aa42b31, 
    author={Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg S and Dean, Jeff},
    booktitle={Advances in Neural Information Processing Systems},
    editor={C.J. Burges and L. Bottou and M. Welling and Z. Ghahramani and K.Q. Weinberger},
    pages={},
    publisher={Curran Associates, Inc.},
    title={Distributed Representations of Words and Phrases and their Compositionality},
    url={https://proceedings.neurips.cc/paper_files/paper/2013/file/9aa42b31882ec039965f3c4923ce901b-Paper.pdf},
    volume={26},
    year={2013},
}

@article{bricken2023monosemanticity, 
    title={Towards Monosemanticity: {Decomposing} Language Models With Dictionary Learning},
    author={Bricken, Trenton and Templeton, Adly and Batson, Joshua and Chen, Brian and Jermyn, Adam and Conerly, Tom and Turner, Nick and Anil, Cem and Denison, Carson and Askell, Amanda and Lasenby, Robert and Wu, Yifan and Kravec, Shauna and Schiefer, Nicholas and Maxwell, Tim and Joseph, Nicholas and Hatfield-Dodds, Zac and Tamkin, Alex and Nguyen, Karina and McLean, Brayden and Burke, Josiah E and Hume, Tristan and Carter, Shan and Henighan, Tom and Olah, Christopher},
    year={2023},
    journal={Transformer Circuits Thread},
    url={https://transformer-circuits.pub/2023/monosemantic-features/index.html},
}

@article{templeton2024scaling, 
    title={Scaling Monosemanticity: {Extracting} Interpretable Features from Claude 3 Sonnet},
    author={Templeton, Adly and Conerly, Tom and Marcus, Jonathan and Lindsey, Jack and Bricken, Trenton and Chen, Brian and Pearce, Adam and Citro, Craig and Ameisen, Emmanuel and Jones, Andy and Cunningham, Hoagy and Turner, Nicholas L and McDougall, Callum and MacDiarmid, Monte and Freeman, C. Daniel and Sumers, Theodore R. and Rees, Edward and Batson, Joshua and Jermyn, Adam and Carter, Shan and Olah, Chris and Henighan, Tom},
    year={2024},
    journal={Transformer Circuits Thread},
    url={https://transformer-circuits.pub/2024/scaling-monosemanticity/index.html},
}

@inproceedings{zheng2024on, 
    title={On Prompt-Driven Safeguarding for Large Language Models},
    author={Chujie Zheng and Fan Yin and Hao Zhou and Fandong Meng and Jie Zhou and Kai-Wei Chang and Minlie Huang and Nanyun Peng},
    booktitle={ICLR 2024 Workshop on Secure and Trustworthy Large Language Models},
    year={2024},
    url={https://openreview.net/forum?id=lFwf7bnpUs},
}

@misc{wolf2024tradeoffsalignmenthelpfulnesslanguage, 
    title={Tradeoffs Between Alignment and Helpfulness in Language Models with Representation Engineering},
    author={Yotam Wolf and Noam Wies and Dorin Shteyman and Binyamin Rothberg and Yoav Levine and Amnon Shashua},
    year={2024},
    eprint={2401.16332},
    archiveprefix={arXiv},
    primaryclass={cs.CL},
    url={https://arxiv.org/abs/2401.16332},
}

@inproceedings{huang-etal-2024-chat, 
    title={Chat Vector: {A} Simple Approach to Equip {LLM}s with Instruction Following and Model Alignment in New Languages},
    author={Huang, Shih-Cheng  and Li, Pin-Zu  and Hsu, Yu-chi  and Chen, Kuang-Ming  and Lin, Yu Tung  and Hsiao, Shih-Kai  and Tsai, Richard  and Lee, Hung-yi},
    editor={Ku, Lun-Wei  and Martins, Andre  and Srikumar, Vivek},
    booktitle={Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
    month={aug},
    year={2024},
    address={Bangkok, Thailand},
    publisher={Association for Computational Linguistics},
    url={https://aclanthology.org/2024.acl-long.590},
    pages={10943--10959},
}

@inproceedings{neurips2023_949f0f8f, 
    author={K\"{o}pf, Andreas and Kilcher, Yannic and von R\"{u}tte, Dimitri and Anagnostidis, Sotiris and Tam, Zhi Rui and Stevens, Keith and Barhoum, Abdullah and Nguyen, Duc and Stanley, Oliver and Nagyfi, Rich\'{a}rd and ES, Shahul and Suri, Sameer and Glushkov, David and Dantuluri, Arnav and Maguire, Andrew and Schuhmann, Christoph and Nguyen, Huu and Mattick, Alexander},
    booktitle={Advances in Neural Information Processing Systems},
    editor={A. Oh and T. Naumann and A. Globerson and K. Saenko and M. Hardt and S. Levine},
    pages={47669--47681},
    publisher={Curran Associates, Inc.},
    title={OpenAssistant Conversations - Democratizing Large Language Model Alignment},
    url={https://proceedings.neurips.cc/paper_files/paper/2023/file/949f0f8f32267d297c2d4e3ee10a2e7e-Paper-Datasets_and_Benchmarks.pdf},
    volume={36},
    year={2023},
}

@inproceedings{pmlr-v202-longpre23a, 
    title={The Flan Collection: {Designing} Data and Methods for Effective Instruction Tuning},
    author={Longpre, Shayne and Hou, Le and Vu, Tu and Webson, Albert and Chung, Hyung Won and Tay, Yi and Zhou, Denny and Le, Quoc V and Zoph, Barret and Wei, Jason and Roberts, Adam},
    booktitle={	 {Proceedings of the 40th International Conference on Machine Learning}},
    pages={	 {22631--22648}},
    year={	 {2023}},
    editor={	 {Krause, Andreas and Brunskill, Emma and Cho, Kyunghyun and Engelhardt, Barbara and Sabato, Sivan and Scarlett, Jonathan}},
    volume={	 {202}},
    series={	 {Proceedings of Machine Learning Research}},
    month={	 {23--29 Jul}},
    publisher={PMLR},
    pdf={	 {https://proceedings.mlr.press/v202/longpre23a/longpre23a.pdf}},
    url={	 {https://proceedings.mlr.press/v202/longpre23a.html}},
    abstract={	 {We study the design decision of publicly available instruction tuning methods, by reproducing and breaking down the development of Flan 2022 (Chung et al., 2022). Through careful ablation studies on the Flan Collection of tasks and methods, we tease apart the effect of design decisions which enable Flan-T5 to outperform prior work by 3-17% across evaluation settings. We find task balancing and enrichment techniques are overlooked but critical to effective instruction tuning, and in particular, training with mixed prompt settings (zero-shot, few-shot, chain-of-thought) actually yields equivalent or stronger (2%) performance in all settings. In further experiments we show Flan-T5 requires less finetuning to converge higher and faster than T5 on single downstream tasks – motivating instruction-tuned models as more computationally-efficient starting checkpoints for new tasks. Finally, to accelerate research on instruction tuning, we make the Flan 2022 collection of datasets, templates, and methods publicly available.}},
}

@inproceedings{ye-etal-2021-crossfit, 
    title={{C}ross{F}it: {A} Few-shot Learning Challenge for Cross-task Generalization in {NLP}},
    author={Ye, Qinyuan  and Lin, Bill Yuchen  and Ren, Xiang},
    editor={Moens, Marie-Francine  and Huang, Xuanjing  and Specia, Lucia  and Yih, Scott Wen-tau},
    booktitle={Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
    month={nov},
    year={2021},
    address={Online and Punta Cana, Dominican Republic},
    publisher={Association for Computational Linguistics},
    url={https://aclanthology.org/2021.emnlp-main.572},
    doi={10.18653/v1/2021.emnlp-main.572},
    pages={7163--7189},
    abstract={Humans can learn a new language task efficiently with only few examples, by leveraging their knowledge obtained when learning prior tasks. In this paper, we explore whether and how such cross-task generalization ability can be acquired, and further applied to build better few-shot learners across diverse NLP tasks. We introduce CrossFit, a problem setup for studying cross-task generalization ability, which standardizes seen/unseen task partitions, data access during different learning stages, and the evaluation protocols. To instantiate different seen/unseen task partitions in CrossFit and facilitate in-depth analysis, we present the NLP Few-shot Gym, a repository of 160 diverse few-shot NLP tasks created from open-access NLP datasets and converted to a unified text-to-text format. Our analysis reveals that the few-shot learning ability on unseen tasks can be improved via an upstream learning stage using a set of seen tasks. We also observe that the selection of upstream learning tasks can significantly influence few-shot performance on unseen tasks, asking further analysis on task similarity and transferability.},
}

@inproceedings{finlayson-etal-2022-makes, 
    title={What Makes Instruction Learning Hard? An Investigation and a New Challenge in a Synthetic Environment},
    author={Finlayson, Matthew  and Richardson, Kyle  and Sabharwal, Ashish  and Clark, Peter},
    editor={Goldberg, Yoav  and Kozareva, Zornitsa  and Zhang, Yue},
    booktitle={Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
    month={dec},
    year={2022},
    address={Abu Dhabi, United Arab Emirates},
    publisher={Association for Computational Linguistics},
    url={https://aclanthology.org/2022.emnlp-main.27},
    doi={10.18653/v1/2022.emnlp-main.27},
    pages={414--426},
}

@inproceedings{gupta-etal-2022-instructdial, 
    title={{I}nstruct{D}ial: {Improving} Zero and Few-shot Generalization in Dialogue through Instruction Tuning},
    author={Gupta, Prakhar  and Jiao, Cathy  and Yeh, Yi-Ting  and Mehri, Shikib  and Eskenazi, Maxine  and Bigham, Jeffrey},
    editor={Goldberg, Yoav  and Kozareva, Zornitsa  and Zhang, Yue},
    booktitle={Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
    month={dec},
    year={2022},
    address={Abu Dhabi, United Arab Emirates},
    publisher={Association for Computational Linguistics},
    url={https://aclanthology.org/2022.emnlp-main.33},
    doi={10.18653/v1/2022.emnlp-main.33},
    pages={505--525},
}

@inproceedings{wang-etal-2022-super, 
    title={Super-{N}atural{I}nstructions: {Generalization} via Declarative Instructions on 1600+ {NLP} Tasks},
    author={Wang, Yizhong  and Mishra, Swaroop  and Alipoormolabashi, Pegah  and Kordi, Yeganeh  and Mirzaei, Amirreza  and Naik, Atharva  and Ashok, Arjun  and Dhanasekaran, Arut Selvan  and Arunkumar, Anjana  and Stap, David  and Pathak, Eshaan  and Karamanolakis, Giannis  and Lai, Haizhi  and Purohit, Ishan  and Mondal, Ishani  and Anderson, Jacob  and Kuznia, Kirby  and Doshi, Krima  and Pal, Kuntal Kumar  and Patel, Maitreya  and Moradshahi, Mehrad  and Parmar, Mihir  and Purohit, Mirali  and Varshney, Neeraj  and Kaza, Phani Rohitha  and Verma, Pulkit  and Puri, Ravsehaj Singh  and Karia, Rushang  and Doshi, Savan  and Sampat, Shailaja Keyur  and Mishra, Siddhartha  and Reddy A, Sujan  and Patro, Sumanta  and Dixit, Tanay  and Shen, Xudong},
    editor={Goldberg, Yoav  and Kozareva, Zornitsa  and Zhang, Yue},
    booktitle={Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
    month={dec},
    year={2022},
    address={Abu Dhabi, United Arab Emirates},
    publisher={Association for Computational Linguistics},
    url={https://aclanthology.org/2022.emnlp-main.340},
    doi={10.18653/v1/2022.emnlp-main.340},
    pages={5085--5109},
    abstract={How well can NLP models generalize to a variety of unseen tasks when provided with task instructions? To address this question, we first introduce Super-NaturalInstructions, a benchmark of 1,616 diverse NLP tasks and their expert-written instructions. Our collection covers 76 distinct task types, including but not limited to classification, extraction, infilling, sequence tagging, text rewriting, and text composition. This large and diverse collection of tasks enables rigorous benchmarking of cross-task generalization under instructions{---}training models to follow instructions on a subset of tasks and evaluating them on the remaining unseen ones.Furthermore, we build Tk-Instruct, a transformer model trained to follow a variety of in-context instructions (plain language task definitions or k-shot examples). Our experiments show that Tk-Instruct outperforms existing instruction-following models such as InstructGPT by over 9{\%} on our benchmark despite being an order of magnitude smaller. We further analyze generalization as a function of various scaling parameters, such as the number of observed tasks, the number of instances per task, and model sizes. We hope our dataset and model facilitate future progress towards more general-purpose NLP models.},
}

@article{chung2024scaling, 
    title={Scaling instruction-finetuned language models},
    author={Chung, Hyung Won and Hou, Le and Longpre, Shayne and Zoph, Barret and Tay, Yi and Fedus, William and Li, Yunxuan and Wang, Xuezhi and Dehghani, Mostafa and Brahma, Siddhartha and others},
    journal={Journal of Machine Learning Research},
    volume={25},
    number={70},
    pages={1--53},
    year={2024},
    url={https://www.jmlr.org/papers/v25/23-0870.html},
}

@article{10.1162/coli_a_00523, 
    author={Lou, Renze and Zhang, Kai and Yin, Wenpeng},
    title={Large Language Model Instruction Following: {A} Survey of Progresses and Challenges},
    journal={Computational Linguistics},
    pages={1-43},
    year={2024},
    month={08},
    issn={0891-2017},
    doi={10.1162/coli_a_00523},
    url={https://doi.org/10.1162/coli\_a\_00523},
    eprint={https://direct.mit.edu/coli/article-pdf/doi/10.1162/coli\_a\_00523/2464827/coli\_a\_00523.pdf},
}

@misc{belrose2023diffinmeans, 
    title={Diff-in-Means Concept Editing is Worst-Case Optimal: {Explaining} a result by {Sam Marks} and {Max Tegmark}},
    author={Belrose, Nora},
    year={2023},
    url={https://blog.eleuther.ai/diff-in-means/},
}

@misc{bai2022traininghelpfulharmlessassistant, 
    title={Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback},
    author={Yuntao Bai and Andy Jones and Kamal Ndousse and Amanda Askell and Anna Chen and Nova DasSarma and Dawn Drain and Stanislav Fort and Deep Ganguli and Tom Henighan and Nicholas Joseph and Saurav Kadavath and Jackson Kernion and Tom Conerly and Sheer El-Showk and Nelson Elhage and Zac Hatfield-Dodds and Danny Hernandez and Tristan Hume and Scott Johnston and Shauna Kravec and Liane Lovitt and Neel Nanda and Catherine Olsson and Dario Amodei and Tom Brown and Jack Clark and Sam McCandlish and Chris Olah and Ben Mann and Jared Kaplan},
    year={2022},
    eprint={2204.05862},
    archiveprefix={arXiv},
    primaryclass={cs.CL},
    url={https://arxiv.org/abs/2204.05862},
}

@misc{askell2021generallanguageassistantlaboratory, 
    title={A General Language Assistant as a Laboratory for Alignment},
    author={Amanda Askell and Yuntao Bai and Anna Chen and Dawn Drain and Deep Ganguli and Tom Henighan and Andy Jones and Nicholas Joseph and Ben Mann and Nova DasSarma and Nelson Elhage and Zac Hatfield-Dodds and Danny Hernandez and Jackson Kernion and Kamal Ndousse and Catherine Olsson and Dario Amodei and Tom Brown and Jack Clark and Sam McCandlish and Chris Olah and Jared Kaplan},
    year={2021},
    eprint={2112.00861},
    archiveprefix={arXiv},
    primaryclass={cs.CL},
    url={https://arxiv.org/abs/2112.00861},
}

@inproceedings{ouyang2022training, 
    title={Training language models to follow instructions with human feedback},
    author={Long Ouyang and Jeffrey Wu and Xu Jiang and Diogo Almeida and Carroll Wainwright and Pamela Mishkin and Chong Zhang and Sandhini Agarwal and Katarina Slama and Alex Gray and John Schulman and Jacob Hilton and Fraser Kelton and Luke Miller and Maddie Simens and Amanda Askell and Peter Welinder and Paul Christiano and Jan Leike and Ryan Lowe},
    booktitle={Advances in Neural Information Processing Systems},
    editor={Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
    year={2022},
    url={https://openreview.net/forum?id=TG8KACxEON},
}

@inproceedings{lee2024a, 
    title={A Mechanistic Understanding of Alignment Algorithms: {A} Case Study on {DPO} and Toxicity},
    author={Andrew Lee and Xiaoyan Bai and Itamar Pres and Martin Wattenberg and Jonathan K. Kummerfeld and Rada Mihalcea},
    booktitle={Forty-first International Conference on Machine Learning},
    year={2024},
    url={https://openreview.net/forum?id=dBqHGZPGZI},
}

@inproceedings{huben2024sparse, 
    title={Sparse Autoencoders Find Highly Interpretable Features in Language Models},
    author={Robert Huben and Hoagy Cunningham and Logan Riggs Smith and Aidan Ewart and Lee Sharkey},
    booktitle={The Twelfth International Conference on Learning Representations},
    year={2024},
    url={https://openreview.net/forum?id=F76bwRSLeK},
}

@misc{sae_finetuning, 
    author={Connor Kissane and Robert Krzyzanowski and Arthur Conmy and Neel Nanda},
    url={https://www.alignmentforum.org/posts/fmwk6qxrpW8d4jvbd/saes-usually-transfer-between-base-and-chat-models},
    year={2024},
    howpublished={Alignment Forum},
    title={{SAEs} (usually) Transfer Between Base and Chat Models},
}

@inproceedings{ilharco2023editing, 
    title={Editing models with task arithmetic},
    author={Gabriel Ilharco and Marco Tulio Ribeiro and Mitchell Wortsman and Ludwig Schmidt and Hannaneh Hajishirzi and Ali Farhadi},
    booktitle={The Eleventh International Conference on Learning Representations },
    year={2023},
    url={https://openreview.net/forum?id=6t0Kwf8-jrj},
}

@inproceedings{scalena2024multipropertysteeringlargelanguage,
    title = "Multi-property Steering of Large Language Models with Dynamic Activation Composition",
    author = "Scalena, Daniel  and
      Sarti, Gabriele  and
      Nissim, Malvina",
    editor = "Belinkov, Yonatan  and
      Kim, Najoung  and
      Jumelet, Jaap  and
      Mohebbi, Hosein  and
      Mueller, Aaron  and
      Chen, Hanjie",
    booktitle = "Proceedings of the 7th BlackboxNLP Workshop: Analyzing and Interpreting Neural Networks for NLP",
    month = nov,
    year = "2024",
    address = "Miami, Florida, US",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.blackboxnlp-1.34/",
    doi = "10.18653/v1/2024.blackboxnlp-1.34",
    pages = "577--603",
    abstract = "Activation steering methods were shown to be effective in conditioning language model generation by additively intervening over models' intermediate representations. However, the evaluation of these techniques has so far been limited to single conditioning properties and synthetic settings. In this work, we conduct a comprehensive evaluation of various activation steering strategies, highlighting the property-dependent nature of optimal parameters to ensure a robust effect throughout generation. To address this issue, we propose Dynamic Activation Composition, an information-theoretic approach to modulate the steering intensity of one or more properties throughout generation. Our experiments on multi-property steering show that our method successfully maintains high conditioning while minimizing the impact of conditioning on generation fluency."
}


@inproceedings{bird-loper-2004-nltk, 
    title={{NLTK}: {The} Natural Language Toolkit},
    author={Bird, Steven  and Loper, Edward},
    booktitle={Proceedings of the {ACL} Interactive Poster and Demonstration Sessions},
    month={jul},
    year={2004},
    address={Barcelona, Spain},
    publisher={Association for Computational Linguistics},
    url={https://aclanthology.org/P04-3031},
    pages={214--217},
}

@misc{jiang2023mistral7b, 
    title={Mistral 7B},
    author={Albert Q. Jiang and Alexandre Sablayrolles and Arthur Mensch and Chris Bamford and Devendra Singh Chaplot and Diego de las Casas and Florian Bressand and Gianna Lengyel and Guillaume Lample and Lucile Saulnier and Lélio Renard Lavaud and Marie-Anne Lachaux and Pierre Stock and Teven Le Scao and Thibaut Lavril and Thomas Wang and Timothée Lacroix and William El Sayed},
    year={2023},
    eprint={2310.06825},
    archiveprefix={arXiv},
    primaryclass={cs.CL},
    url={https://arxiv.org/abs/2310.06825},
}

@misc{abdin2024phi3technicalreporthighly, 
    title={Phi-3 Technical Report: {A} Highly Capable Language Model Locally on Your Phone},
    author={Marah Abdin and Jyoti Aneja and Hany Awadalla and Ahmed Awadallah and Ammar Ahmad Awan and Nguyen Bach and Amit Bahree and Arash Bakhtiari and Jianmin Bao and Harkirat Behl and Alon Benhaim and Misha Bilenko and Johan Bjorck and Sébastien Bubeck and Martin Cai and Qin Cai and Vishrav Chaudhary and Dong Chen and Dongdong Chen and Weizhu Chen and Yen-Chun Chen and Yi-Ling Chen and Hao Cheng and Parul Chopra and Xiyang Dai and Matthew Dixon and Ronen Eldan and Victor Fragoso and Jianfeng Gao and Mei Gao and Min Gao and Amit Garg and Allie Del Giorno and Abhishek Goswami and Suriya Gunasekar and Emman Haider and Junheng Hao and Russell J. Hewett and Wenxiang Hu and Jamie Huynh and Dan Iter and Sam Ade Jacobs and Mojan Javaheripi and Xin Jin and Nikos Karampatziakis and Piero Kauffmann and Mahoud Khademi and Dongwoo Kim and Young Jin Kim and Lev Kurilenko and James R. Lee and Yin Tat Lee and Yuanzhi Li and Yunsheng Li and Chen Liang and Lars Liden and Xihui Lin and Zeqi Lin and Ce Liu and Liyuan Liu and Mengchen Liu and Weishung Liu and Xiaodong Liu and Chong Luo and Piyush Madan and Ali Mahmoudzadeh and David Majercak and Matt Mazzola and Caio César Teodoro Mendes and Arindam Mitra and Hardik Modi and Anh Nguyen and Brandon Norick and Barun Patra and Daniel Perez-Becker and Thomas Portet and Reid Pryzant and Heyang Qin and Marko Radmilac and Liliang Ren and Gustavo de Rosa and Corby Rosset and Sambudha Roy and Olatunji Ruwase and Olli Saarikivi and Amin Saied and Adil Salim and Michael Santacroce and Shital Shah and Ning Shang and Hiteshi Sharma and Yelong Shen and Swadheen Shukla and Xia Song and Masahiro Tanaka and Andrea Tupini and Praneetha Vaddamanu and Chunyu Wang and Guanhua Wang and Lijuan Wang and Shuohang Wang and Xin Wang and Yu Wang and Rachel Ward and Wen Wen and Philipp Witte and Haiping Wu and Xiaoxia Wu and Michael Wyatt and Bin Xiao and Can Xu and Jiahang Xu and Weijian Xu and Jilong Xue and Sonali Yadav and Fan Yang and Jianwei Yang and Yifan Yang and Ziyi Yang and Donghan Yu and Lu Yuan and Chenruidong Zhang and Cyril Zhang and Jianwen Zhang and Li Lyna Zhang and Yi Zhang and Yue Zhang and Yunan Zhang and Xiren Zhou},
    year={2024},
    eprint={2404.14219},
    archiveprefix={arXiv},
    primaryclass={cs.CL},
    url={https://arxiv.org/abs/2404.14219},
}

@misc{gemmateam2024gemma2improvingopen, 
    title={Gemma 2: {Improving} Open Language Models at a Practical Size},
    author={{Gemma Team}},
    year={2024},
    eprint={2408.00118},
    archiveprefix={arXiv},
    primaryclass={cs.CL},
    url={https://arxiv.org/abs/2408.00118},
}

@misc{openai2024gpt4technicalreport, 
    title={{GPT-4} Technical Report},
    author={OpenAI},
    year={2024},
    eprint={2303.08774},
    archiveprefix={arXiv},
    primaryclass={cs.CL},
    url={https://arxiv.org/abs/2303.08774},
}

@inproceedings{marks2024the, 
    title={The Geometry of Truth: {Emergent} Linear Structure in Large Language Model Representations of True/False Datasets},
    author={Samuel Marks and Max Tegmark},
    booktitle={First Conference on Language Modeling},
    year={2024},
    url={https://openreview.net/forum?id=aajyHYjjsk},
}

@article{elhage2021mathematical, 
    title={A Mathematical Framework for Transformer Circuits},
    author={Elhage, Nelson and Nanda, Neel and Olsson, Catherine and Henighan, Tom and Joseph, Nicholas and Mann, Ben and Askell, Amanda and Bai, Yuntao and Chen, Anna and Conerly, Tom and DasSarma, Nova and Drain, Dawn and Ganguli, Deep and Hatfield-Dodds, Zac and Hernandez, Danny and Jones, Andy and Kernion, Jackson and Lovitt, Liane and Ndousse, Kamal and Amodei, Dario and Brown, Tom and Clark, Jack and Kaplan, Jared and McCandlish, Sam and Olah, Chris},
    year={2021},
    journal={Transformer Circuits Thread},
    url={https://transformer-circuits.pub/2021/framework/index.html},
}

@inproceedings{hernandez2024inspecting, 
    title={Inspecting and Editing Knowledge Representations in Language Models},
    author={Evan Hernandez and Belinda Z. Li and Jacob Andreas},
    booktitle={First Conference on Language Modeling},
    year={2024},
    url={https://openreview.net/forum?id=ADtL6fgNRv},
}

@inproceedings{subramani-etal-2022-extracting, 
    title={Extracting Latent Steering Vectors from Pretrained Language Models},
    author={Subramani, Nishant  and Suresh, Nivedita  and Peters, Matthew},
    editor={Muresan, Smaranda  and Nakov, Preslav  and Villavicencio, Aline},
    booktitle={Findings of the Association for Computational Linguistics: ACL 2022},
    month={may},
    year={2022},
    address={Dublin, Ireland},
    publisher={Association for Computational Linguistics},
    url={https://aclanthology.org/2022.findings-acl.48},
    doi={10.18653/v1/2022.findings-acl.48},
    pages={566--581},
}

@inproceedings{dathathri2020plug, 
    title={Plug and Play Language Models: {A} Simple Approach to Controlled Text Generation},
    author={Sumanth Dathathri and Andrea Madotto and Janice Lan and Jane Hung and Eric Frank and Piero Molino and Jason Yosinski and Rosanne Liu},
    booktitle={International Conference on Learning Representations},
    year={2020},
    url={https://openreview.net/forum?id=H1edEyBKDS},
}

@inproceedings{li2024measuring, 
    title={Measuring and Controlling Instruction (In)Stability in Language Model Dialogs},
    author={Kenneth Li and Tianle Liu and Naomi Bashkansky and David Bau and Fernanda Vi{\'e}gas and Hanspeter Pfister and Martin Wattenberg},
    booktitle={First Conference on Language Modeling},
    year={2024},
    url={https://openreview.net/forum?id=60a1SAtH4e},
}


@InProceedings{pmlr-v202-zhou23g,
  title = 	 {Controlled Text Generation with Natural Language Instructions},
  author =       {Zhou, Wangchunshu and Jiang, Yuchen Eleanor and Wilcox, Ethan and Cotterell, Ryan and Sachan, Mrinmaya},
  booktitle = 	 {Proceedings of the 40th International Conference on Machine Learning},
  pages = 	 {42602--42613},
  year = 	 {2023},
  editor = 	 {Krause, Andreas and Brunskill, Emma and Cho, Kyunghyun and Engelhardt, Barbara and Sabato, Sivan and Scarlett, Jonathan},
  volume = 	 {202},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {23--29 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v202/zhou23g/zhou23g.pdf},
  url = 	 {https://proceedings.mlr.press/v202/zhou23g.html},
  abstract = 	 {Large language models can be prompted to pro- duce fluent output for a wide range of tasks without being specifically trained to do so. Nevertheless, it is notoriously difficult to control their generation in such a way that it satisfies user-specified constraints. In this paper, we present InstructCTG, a simple controlled text generation framework that incorporates different constraints by verbalizing them as natural language instructions. We annotate natural texts through a combination of off-the-shelf NLP tools and simple heuristics with the linguistic and extra-linguistic constraints they satisfy. Then, we verbalize the constraints into natural language instructions to form weakly supervised training data, i.e., we prepend the natural language verbalizations of the constraints in front of their corresponding natural language sentences. Next, we fine-tune a pre-trained language model on the augmented corpus. Compared to existing methods, InstructCTG is more flexible in terms of the types of constraints it allows the practitioner to use. It also does not require any modification of the decoding procedure. Finally, InstructCTG allows the model to adapt to new constraints without re-training through the use of in-context learning.}
}


@inproceedings{wei2022finetuned, 
    title={Finetuned Language Models are Zero-Shot Learners},
    author={Jason Wei and Maarten Bosma and Vincent Zhao and Kelvin Guu and Adams Wei Yu and Brian Lester and Nan Du and Andrew M. Dai and Quoc V Le},
    booktitle={International Conference on Learning Representations},
    year={2022},
    url={https://openreview.net/forum?id=gEZrGCozdqR},
}

@misc{zhou2023instruction, 
    title={Instruction-Following Evaluation for Large Language Models},
    author={Jeffrey Zhou and Tianjian Lu and Swaroop Mishra and Siddhartha Brahma and Sujoy Basu and Yi Luan and Denny Zhou and Le Hou},
    year={2023},
    eprint={2311.07911},
    archiveprefix={arXiv},
    primaryclass={cs.CL},
    url={https://arxiv.org/abs/2311.07911},
}

@inproceedings{sanh2022multitask, 
    title={Multitask Prompted Training Enables Zero-Shot Task Generalization},
    author={Victor Sanh and Albert Webson and Colin Raffel and Stephen Bach and Lintang Sutawika and Zaid Alyafeai and Antoine Chaffin and Arnaud Stiegler and Arun Raja and Manan Dey and M Saiful Bari and Canwen Xu and Urmish Thakker and Shanya Sharma Sharma and Eliza Szczechla and Taewoon Kim and Gunjan Chhablani and Nihal Nayak and Debajyoti Datta and Jonathan Chang and Mike Tian-Jian Jiang and Han Wang and Matteo Manica and Sheng Shen and Zheng Xin Yong and Harshit Pandey and Rachel Bawden and Thomas Wang and Trishala Neeraj and Jos Rozen and Abheesht Sharma and Andrea Santilli and Thibault Fevry and Jason Alan Fries and Ryan Teehan and Teven Le Scao and Stella Biderman and Leo Gao and Thomas Wolf and Alexander M Rush},
    booktitle={International Conference on Learning Representations},
    year={2022},
    url={https://openreview.net/forum?id=9Vrb9D0WI4},
}

@inproceedings{li2023inferencetime, 
    title={Inference-Time Intervention: {Eliciting} Truthful Answers from a Language Model},
    author={Kenneth Li and Oam Patel and Fernanda Vi{\'e}gas and Hanspeter Pfister and Martin Wattenberg},
    booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
    year={2023},
    url={https://openreview.net/forum?id=aLLuYpn83y},
}

@misc{tigges2024language, 
    title={Language Models Linearly Represent Sentiment},
    author={Curt Tigges and Oskar John Hollinsworth and Neel Nanda and Atticus Geiger},
    year={2024},
    url={https://openreview.net/forum?id=iGDWZFc7Ya},
}

@inproceedings{liu2024incontext, 
    title={In-context Vectors: {Making} In Context Learning More Effective and Controllable Through Latent Space Steering},
    author={Sheng Liu and Haotian Ye and Lei Xing and James Y. Zou},
    booktitle={Forty-first International Conference on Machine Learning},
    year={2024},
    url={https://openreview.net/forum?id=dJTChKgv3a},
}

@misc{zou2023repr, 
    title={Representation Engineering: {A} Top-Down Approach to {AI} Transparency},
    author={Andy Zou and Long Phan and Sarah Chen and James Campbell and Phillip Guo and Richard Ren and Alexander Pan and Xuwang Yin and Mantas Mazeika and Ann-Kathrin Dombrowski and Shashwat Goel and Nathaniel Li and Michael J. Byun and Zifan Wang and Alex Mallen and Steven Basart and Sanmi Koyejo and Dawn Song and Matt Fredrikson and J. Zico Kolter and Dan Hendrycks},
    year={2023},
    eprint={2310.01405},
    archiveprefix={arXiv},
    primaryclass={cs.LG},
    url={https://arxiv.org/abs/2310.01405},
}

@inproceedings{mishra-etal-2022-cross, 
    title={Cross-Task Generalization via Natural Language Crowdsourcing Instructions},
    author={Mishra, Swaroop  and Khashabi, Daniel  and Baral, Chitta  and Hajishirzi, Hannaneh},
    editor={Muresan, Smaranda  and Nakov, Preslav  and Villavicencio, Aline},
    booktitle={Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
    month={may},
    year={2022},
    address={Dublin, Ireland},
    publisher={Association for Computational Linguistics},
    url={https://aclanthology.org/2022.acl-long.244},
    doi={10.18653/v1/2022.acl-long.244},
    pages={3470--3487},
}

@article{zhang2023survey, 
    author={Zhang, Hanqing and Song, Haolin and Li, Shaoyu and Zhou, Ming and Song, Dawei},
    title={A Survey of Controllable Text Generation Using Transformer-based Pre-trained Language Models},
    year={2023},
    issue_date={March 2024},
    publisher={Association for Computing Machinery},
    address={New York, NY, USA},
    volume={56},
    number={3},
    issn={0360-0300},
    url={https://doi.org/10.1145/3617680},
    doi={10.1145/3617680},
    journal={ACM Comput. Surv.},
    month={oct},
    articleno={64},
    numpages={37},
    keywords={Controllable text generation, pre-trained language models, Transformer, controllability, systematic review},
}

@inproceedings{rimsky-etal-2024-steering, 
    title={Steering Llama 2 via Contrastive Activation Addition},
    author={Panickssery, Nina  and Gabrieli, Nick  and Schulz, Julian  and Tong, Meg  and Hubinger, Evan  and Turner, Alexander},
    editor={Ku, Lun-Wei  and Martins, Andre  and Srikumar, Vivek},
    booktitle={Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
    month={aug},
    year={2024},
    address={Bangkok, Thailand},
    publisher={Association for Computational Linguistics},
    url={https://aclanthology.org/2024.acl-long.828},
    pages={15504--15522},
}

@article{turner2023activation, 
    title={Activation addition: {Steering} language models without optimization},
    author={Turner, Alexander Matt and Thiergart, Lisa and Leech, Gavin and Udell, David and Vazquez, Juan J and Mini, Ulisse and MacDiarmid, Monte},
    journal={arXiv preprint arXiv:2308.10248},
    url={https://arxiv.org/abs/2308.10248},
    year={2023},
}

@inproceedings{
arditi2024refusal,
title={Refusal in Language Models Is Mediated by a Single Direction},
author={Andy Arditi and Oscar Balcells Obeso and Aaquib Syed and Daniel Paleka and Nina Rimsky and Wes Gurnee and Neel Nanda},
booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
year={2024},
url={https://openreview.net/forum?id=pH3XAQME6c}
}

@inproceedings{sun-etal-2023-evaluating, 
    title={Evaluating Large Language Models on Controlled Generation Tasks},
    author={Sun, Jiao  and Tian, Yufei  and Zhou, Wangchunshu  and Xu, Nan  and Hu, Qian  and Gupta, Rahul  and Wieting, John  and Peng, Nanyun  and Ma, Xuezhe},
    editor={Bouamor, Houda  and Pino, Juan  and Bali, Kalika},
    booktitle={Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
    month={dec},
    year={2023},
    address={Singapore},
    publisher={Association for Computational Linguistics},
    url={https://aclanthology.org/2023.emnlp-main.190},
    doi={10.18653/v1/2023.emnlp-main.190},
    pages={3155--3168},
}

@inproceedings{hendel-etal-2023-context, 
    title={In-Context Learning Creates Task Vectors},
    author={Hendel, Roee  and Geva, Mor  and Globerson, Amir},
    editor={Bouamor, Houda  and Pino, Juan  and Bali, Kalika},
    booktitle={Findings of the Association for Computational Linguistics: EMNLP 2023},
    month={dec},
    year={2023},
    address={Singapore},
    publisher={Association for Computational Linguistics},
    url={https://aclanthology.org/2023.findings-emnlp.624},
    doi={10.18653/v1/2023.findings-emnlp.624},
    pages={9318--9333},
}

@inproceedings{todd2024function, 
    title={Function Vectors in Large Language Models},
    author={Eric Todd and Millicent Li and Arnab Sen Sharma and Aaron Mueller and Byron C Wallace and David Bau},
    booktitle={The Twelfth International Conference on Learning Representations},
    year={2024},
    url={https://openreview.net/forum?id=AwyxtyMwaG},
}

@inproceedings{
prakash2024finetuning,
title={Fine-Tuning Enhances Existing Mechanisms: A Case Study on Entity Tracking},
author={Nikhil Prakash and Tamar Rott Shaham and Tal Haklay and Yonatan Belinkov and David Bau},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=8sKcAWOf2D}
}

@inproceedings{
stolfo2025improving,
title={Improving Instruction-Following in Language Models through Activation Steering},
author={Alessandro Stolfo and Vidhisha Balachandran and Safoora Yousefi and Eric Horvitz and Besmira Nushi},
booktitle={The Thirteenth International Conference on Learning Representations},
year={2025},
url={https://openreview.net/forum?id=wozhdnRCtw}
}

@inproceedings{kwon2023efficient,
  title={Efficient Memory Management for Large Language Model Serving with PagedAttention},
  author={Woosuk Kwon and Zhuohan Li and Siyuan Zhuang and Ying Sheng and Lianmin Zheng and Cody Hao Yu and Joseph E. Gonzalez and Hao Zhang and Ion Stoica},
  booktitle={Proceedings of the ACM SIGOPS 29th Symposium on Operating Systems Principles},
  year={2023}
}

@article{fiottokaufman2024nnsightndifdemocratizingaccess,
      title={NNsight and NDIF: Democratizing Access to Foundation Model Internals}, 
      author={Jaden Fiotto-Kaufman and Alexander R Loftus and Eric Todd and Jannik Brinkmann and Caden Juang and Koyena Pal and Can Rager and Aaron Mueller and Samuel Marks and Arnab Sen Sharma and Francesca Lucchetti and Michael Ripa and Adam Belfki and Nikhil Prakash and Sumeet Multani and Carla Brodley and Arjun Guha and Jonathan Bell and Byron Wallace and David Bau},
      year={2024},
      eprint={2407.14561},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2407.14561}, 
}

@misc{wu2025understandingllmsfluidintelligence,
      title={Understanding LLMs' Fluid Intelligence Deficiency: An Analysis of the ARC Task}, 
      author={Junjie Wu and Mo Yu and Lemao Liu and Dit-Yan Yeung and Jie Zhou},
      year={2025},
      eprint={2502.07190},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2502.07190}, 
}

@article{fluid,
  author  = {Ferrer, E. and O'Hare, E. D. and Bunge, S. A.},
  title   = {Fluid reasoning and the developing brain},
  journal = {Frontiers in Neuroscience},
  year    = {2009},
  volume  = {3},
  number  = {1},
  pages   = {46--51},
  month   = may,
  doi     = {10.3389/neuro.01.003.2009},
  pmid    = {19753096},
  pmcid   = {PMC2858618}
}
@misc{chollet2025arcagi2newchallengefrontier,
      title={ARC-AGI-2: A New Challenge for Frontier AI Reasoning Systems}, 
      author={Francois Chollet and Mike Knoop and Gregory Kamradt and Bryan Landers and Henry Pinkard},
      year={2025},
      eprint={2505.11831},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2505.11831}, 
}
@misc{chollet2019measureintelligence,
      title={On the Measure of Intelligence}, 
      author={François Chollet},
      year={2019},
      eprint={1911.01547},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/1911.01547}, 
}
@misc{seed2025seed-oss,
  author={ByteDance-Seed-Team},
  title={Seed-OSS Open-Source Models},
  year={2025},
  howpublished={\url{https://github.com/ByteDance-Seed/seed-oss}}
}